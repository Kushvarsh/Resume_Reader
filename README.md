# Resume_Reader

This project is a Streamlit-based Resume Information Extractor that uses a Large Language Model (LLM) integrated through LangChain and Groq to convert unstructured resume text into structured data. The main objective of this application is to demonstrate how LLMs can be guided to generate consistent, validated outputs using a Pydantic schema and output parser.

The application allows users to paste resume content into a text area in the Streamlit interface. Once the user clicks the “Extract Information” button, the resume text is sent to the LLM along with formatting instructions generated by the PydanticOutputParser. These formatting instructions ensure that the model returns the response in a predefined structured format.

A Pydantic model named “Information” defines the required fields: candidate name, educational qualifications, work experience (optional), skills (optional), and total years of work experience. This schema enforces data types and ensures validation of the LLM output. The PydanticOutputParser plays a crucial role by both instructing the LLM on the expected format and parsing the response into a structured Python object.

The ChatGroq model is configured with a moderate temperature to balance creativity and accuracy. The PromptTemplate combines the resume text with structured format instructions before sending it to the model.

The extracted information is displayed clearly on the Streamlit interface, making the application user-friendly and interactive. Error handling is also included to manage parsing failures.

Overall, this project demonstrates practical implementation of structured LLM outputs, prompt engineering, schema validation, and web app deployment using Streamlit, making it suitable for resume parsing, ATS systems, and HR automation tools.
